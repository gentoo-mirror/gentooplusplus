# Example ENV config
LLAMA_HOST="0.0.0.0"
LLAMA_PORT="11444"
LLAMA_MODEL="/opt/llama-cpp/models/mymodel.gguf"
LLAMA_ARGS="--n-gpu-layers 999 --ctx-size 4096 --flash-attn on"

